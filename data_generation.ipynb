{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d1cf5-c592-4975-bb4b-bf7638f7b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PATH=/scratch/x2989a04/ollama/bin:$PATH\n",
    "!export LD_LIBRARY_PATH=/scratch/x2989a04/ollama/lib/ollama:$LD_LIBRARY_PATH\n",
    "import ollama\n",
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf842cdf-6c46-423f-8ebe-8c9709a67cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#text = ollama.generate(model='llama3.3', prompt='Generate example data(column, row) in CSV format')\n",
    "text = ollama.chat(model='llama3.1-medical-v2', messages=[{'role': 'user', 'content': 'Generate sample data (columns, rows) in CSV format. No explanation required.'}])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73326f04-e943-4651-aff8-278481c4952b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target length: 3665\n",
      "Initial synthetic data length: 931\n",
      "Current synthetic data length: 955\n",
      "Current synthetic data length: 978\n",
      "Current synthetic data length: 1020\n",
      "Current synthetic data length: 1051\n",
      "Current synthetic data length: 1084\n",
      "Current synthetic data length: 1111\n",
      "Current synthetic data length: 1132\n",
      "Current synthetic data length: 1192\n",
      "Current synthetic data length: 1237\n",
      "Current synthetic data length: 1257\n",
      "Current synthetic data length: 1278\n",
      "Current synthetic data length: 1293\n",
      "Current synthetic data length: 1314\n",
      "Current synthetic data length: 1340\n",
      "Current synthetic data length: 1358\n",
      "Current synthetic data length: 1374\n",
      "Current synthetic data length: 1389\n",
      "Current synthetic data length: 1410\n",
      "Current synthetic data length: 1432\n",
      "Current synthetic data length: 1453\n",
      "Current synthetic data length: 1476\n",
      "Current synthetic data length: 1512\n",
      "Current synthetic data length: 1533\n",
      "Current synthetic data length: 1582\n",
      "Current synthetic data length: 1596\n",
      "Current synthetic data length: 1616\n",
      "Current synthetic data length: 1636\n",
      "Current synthetic data length: 1652\n",
      "Current synthetic data length: 1664\n",
      "Current synthetic data length: 1688\n",
      "Current synthetic data length: 1707\n",
      "Current synthetic data length: 1729\n",
      "Current synthetic data length: 1751\n",
      "Current synthetic data length: 1772\n",
      "Current synthetic data length: 1793\n",
      "Current synthetic data length: 1808\n",
      "Current synthetic data length: 1846\n",
      "Current synthetic data length: 1858\n",
      "Current synthetic data length: 1873\n",
      "Current synthetic data length: 1889\n",
      "Current synthetic data length: 1903\n",
      "Current synthetic data length: 1922\n",
      "Current synthetic data length: 1944\n",
      "Current synthetic data length: 1965\n",
      "Current synthetic data length: 1993\n",
      "Current synthetic data length: 2033\n",
      "Current synthetic data length: 2052\n",
      "Current synthetic data length: 2073\n",
      "Current synthetic data length: 2089\n",
      "Current synthetic data length: 2110\n",
      "Current synthetic data length: 2137\n",
      "Current synthetic data length: 2147\n",
      "Current synthetic data length: 2168\n",
      "Current synthetic data length: 2214\n",
      "Current synthetic data length: 2230\n",
      "Current synthetic data length: 2267\n",
      "Current synthetic data length: 2288\n",
      "Current synthetic data length: 2321\n",
      "Current synthetic data length: 2362\n",
      "Current synthetic data length: 2383\n",
      "Current synthetic data length: 2397\n",
      "Current synthetic data length: 2422\n",
      "Current synthetic data length: 2438\n",
      "Current synthetic data length: 2517\n",
      "Current synthetic data length: 2537\n",
      "Current synthetic data length: 2572\n",
      "Current synthetic data length: 2604\n",
      "Current synthetic data length: 2619\n",
      "Current synthetic data length: 2629\n",
      "Current synthetic data length: 2652\n",
      "Current synthetic data length: 2673\n",
      "Current synthetic data length: 2692\n",
      "Current synthetic data length: 2718\n",
      "Current synthetic data length: 2733\n",
      "Current synthetic data length: 2749\n",
      "Current synthetic data length: 2764\n",
      "Current synthetic data length: 2779\n",
      "Current synthetic data length: 2796\n",
      "Current synthetic data length: 2829\n",
      "Current synthetic data length: 2854\n",
      "Current synthetic data length: 2874\n",
      "Current synthetic data length: 2937\n",
      "Current synthetic data length: 2952\n",
      "Current synthetic data length: 2972\n",
      "Current synthetic data length: 2993\n",
      "Current synthetic data length: 3043\n",
      "Current synthetic data length: 3076\n",
      "Current synthetic data length: 3098\n",
      "Current synthetic data length: 3119\n",
      "Current synthetic data length: 3154\n",
      "Current synthetic data length: 3178\n",
      "Current synthetic data length: 3193\n",
      "Current synthetic data length: 3214\n",
      "Current synthetic data length: 3229\n",
      "Current synthetic data length: 3245\n",
      "Current synthetic data length: 3259\n",
      "Current synthetic data length: 3282\n",
      "Current synthetic data length: 3297\n",
      "Current synthetic data length: 3330\n",
      "Current synthetic data length: 3357\n",
      "Current synthetic data length: 3375\n",
      "Current synthetic data length: 3396\n",
      "Current synthetic data length: 3441\n",
      "Current synthetic data length: 3465\n",
      "Current synthetic data length: 3490\n",
      "Current synthetic data length: 3506\n",
      "Current synthetic data length: 3551\n",
      "Current synthetic data length: 3571\n",
      "Current synthetic data length: 3606\n",
      "Current synthetic data length: 3630\n",
      "Current synthetic data length: 3652\n",
      "Current synthetic data length: 3668\n",
      "Final synthetic data length: 3665\n",
      "Synthetic data saved to 'synthetic_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "def analyze_data(df, binary_columns=['REAL_STONE']):\n",
    "    \"\"\"\n",
    "    Analyzes the dataset and returns summary statistics in the format:\n",
    "    - For binary variables: count and percentage for each group\n",
    "    - For continuous variables: mean and interquartile range (Q1-Q3)\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    # Split by REAL_STONE (CBD stone presence)\n",
    "    groups = {\n",
    "        'CBD stone': df[df['REAL_STONE'] == 1],\n",
    "        'No CBD stone': df[df['REAL_STONE'] == 0]\n",
    "    }\n",
    "    \n",
    "    summary['Total Samples'] = {key: len(value) for key, value in groups.items()}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col == 'REAL_STONE':\n",
    "            continue\n",
    "        \n",
    "        column_stats = {}\n",
    "        \n",
    "        if col in binary_columns:\n",
    "            for group_name, group_df in groups.items():\n",
    "                counts = group_df[col].value_counts()\n",
    "                total = len(group_df)\n",
    "                column_stats[group_name] = {\n",
    "                    f'{int(val)}': f'{count} ({count/total*100:.2f}%)' for val, count in counts.items()\n",
    "                }\n",
    "        else:\n",
    "            for group_name, group_df in groups.items():\n",
    "                q1 = group_df[col].quantile(0.25)\n",
    "                median = group_df[col].median()\n",
    "                q3 = group_df[col].quantile(0.75)\n",
    "                mean = group_df[col].mean()\n",
    "                column_stats[group_name] = f'{mean:.1f} ({q1:.1f}-{q3:.1f})'\n",
    "                \n",
    "        summary[col] = column_stats\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def generate_prompt_from_data(df, times, retry=False):\n",
    " \n",
    "    class_description = analyze_data(df, binary_columns=['PANCREATITIS', 'DUCT_DILIATATION_8MM','DUCT_DILIATATION_10MM','SEX','REAL_STONE'])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Context:\n",
    "        - You are an advanced AI model specializing in generating high-quality synthetic medical data.\n",
    "        - Your primary task is to generate synthetic patient records to support a predictive model for common bile duct stones (CBDS).\n",
    "        - Ensure the generated data maintains realistic distributions, correlations, and medically relevant patterns based on clinical knowledge.\n",
    "        - The dataset must reflect real-world medical trends while covering diverse patient profiles.\n",
    "\n",
    "        Medical Data Guidelines:\n",
    "        1. **Balance**: The dataset must maintain a 50:50 ratio for the target variable **REAL_STONE** (1 = presence of stone, 0 = absence of stone).\n",
    "        2. **Feature Correlations**:\n",
    "           - Patients with **REAL_STONE = 1** tend to be older and have higher values in liver function tests (**AST, ALT, ALP**), **total bilirubin**, and **bile duct diameter** (>10 mm).\n",
    "           - Patients with **REAL_STONE = 0** tend to exhibit opposite trends, with lower liver function values and bile duct diameters typically ≤10 mm.\n",
    "        3. **Data Constraints**:\n",
    "           - Maintain realistic medical values based on real-world observations.\n",
    "           - Avoid generating extreme outliers or biologically implausible values (e.g., negative lab results, bilirubin >50 mg/dL, ALP 1000 IU/L unless justified).\n",
    "           - Ensure no duplicate records while maximizing variability.\n",
    "\n",
    "        Output Format:\n",
    "        - Strictly output a **CSV-formatted table** with appropriate column headers and data rows.\n",
    "        - Do NOT include explanations, headers, or descriptions—only raw CSV data.\n",
    "\n",
    "        Example Dataset Overview:\n",
    "        {class_description}\n",
    "\n",
    "        Sample Data Structure (Reference):\n",
    "        {df.head(1)}\n",
    "\n",
    "        {\"WARNING: Your previous response was not in CSV format. Ensure this output is STRICTLY CSV format!\" if retry else \"\"}\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generate_synthetic_csv(df, model='llama3.3', times=1):\n",
    "    retry_count = 0\n",
    "    max_retries = 3  # 최대 3번 재시도\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        prompt = generate_prompt_from_data(df, times, retry=(retry_count > 0))\n",
    "        response = ollama.chat(model=model, messages=[{'role': 'user', 'content': prompt}])\n",
    "\n",
    "        synthetic_data = response.message.content.strip()  # 불필요한 줄 제거\n",
    "\n",
    "        try:\n",
    "            # CSV 포맷 검증\n",
    "            synthetic_df = pd.read_csv(StringIO(synthetic_data))\n",
    "            return synthetic_df  # CSV가 정상적으로 변환되면 반환\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing synthetic data (attempt {retry_count + 1}): {e}\")\n",
    "            print(\"Generated Data Preview:\\n\", synthetic_data[:500])\n",
    "            retry_count += 1\n",
    "\n",
    "    raise ValueError(\"Failed to generate valid CSV after multiple attempts.\")\n",
    "\n",
    "def main():\n",
    "    # columns = ['FIRST_HR', 'FIRST_BT', 'AGE', 'DUCT_DILIATATION_10MM', 'Hb', 'PLT', 'WBC', 'ALP', 'ALT', 'AST', 'BILIRUBIN', 'REAL_STONE']\n",
    "    columns = ['PANCREATITIS', 'DUCT_DILIATATION_8MM', 'REAL_STONE',\n",
    "       'DUCT_DILIATATION_10MM', 'SEX', 'AGE', 'FIRST_SBP', 'FIRST_DBP',\n",
    "       'FIRST_HR', 'FIRST_RR', 'FIRST_BT', 'Hb', 'WBC', 'PLT', 'BILIRUBIN',\n",
    "       'AST', 'ALT', 'ALP', 'GGT', 'BUN', 'CREATININE']\n",
    "    df = pd.read_csv('DUMC_project/DUMC_total/dumc_1223_case3_duct_correct.csv')\n",
    "    df = df[columns]\n",
    "\n",
    "    \n",
    "    target_length = len(df) * 5\n",
    "    print(f\"Target length: {target_length}\")\n",
    "\n",
    "    # 기존 synthetic_data.csv 파일이 존재하면 불러오기\n",
    "    if os.path.exists('synthetic_data.csv'):\n",
    "        all_synthetic_data = pd.read_csv('synthetic_data.csv', header=0)\n",
    "    else:\n",
    "        all_synthetic_data = df.copy()\n",
    "        all_synthetic_data.to_csv('synthetic_data.csv', index=False)\n",
    "\n",
    "    current_length = len(all_synthetic_data)\n",
    "    print(f\"Initial synthetic data length: {current_length}\")\n",
    "\n",
    "    while current_length < target_length:\n",
    "        try:\n",
    "            synthetic_df = generate_synthetic_csv(df, model='llama3.1-medical-v2', times=1)\n",
    "            all_synthetic_data = pd.concat([all_synthetic_data, synthetic_df], ignore_index=True).drop_duplicates()\n",
    "            current_length = len(all_synthetic_data)\n",
    "            all_synthetic_data.to_csv('synthetic_data.csv', index=False)\n",
    "            print(f\"Current synthetic data length: {current_length}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to generate valid CSV: {e}. Retrying...\")\n",
    "            continue\n",
    "\n",
    "    # 목표 길이에 정확히 맞추기\n",
    "    if current_length > target_length:\n",
    "        all_synthetic_data = all_synthetic_data.sample(n=target_length, random_state=42)\n",
    "        all_synthetic_data.to_csv('synthetic_data.csv', index=False)\n",
    "        print(f\"Final synthetic data length: {len(all_synthetic_data)}\")\n",
    "\n",
    "    print(f\"Synthetic data saved to 'synthetic_data.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79252a75-d243-410d-a56c-2fa8584cd28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def remove_outliers_iqr(df, threshold=1.5):\n",
    "    \"\"\"\n",
    "    IQR(Interquartile Range) 방법을 사용하여 이상치를 제거하는 함수\n",
    "    - threshold: 이상치 판별 기준 (default: 1.5)\n",
    "    \"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns  # 숫자형 컬럼만 처리\n",
    "    initial_size = len(df)\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "        # 이상치 제거\n",
    "        filtered_df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "        if len(df) == 0:  # 데이터가 비어 있으면 중단\n",
    "            print(f\"Warning: '{col}' 제거 후 데이터가 비어 있음. 원본 데이터 유지.\")\n",
    "            return df  # 원본 데이터 반환\n",
    "\n",
    "        # 이상치 비율 계산 (ZeroDivisionError 방지)\n",
    "        if len(df) > 0:\n",
    "            outlier_ratio = (1 - len(filtered_df) / len(df)) * 100\n",
    "            if outlier_ratio < 10:\n",
    "                df = filtered_df\n",
    "            else:\n",
    "                print(f\"Skipping outlier removal for '{col}' (outlier ratio: {outlier_ratio:.2f}%)\")\n",
    "\n",
    "    removed_count = initial_size - len(df)\n",
    "    print(f\"Total outliers removed: {removed_count}\")\n",
    "    return df\n",
    "\n",
    "def preprocess_synthetic_data(input_file='synthetic_data.csv', output_file='synthetic_data_preprocessed.csv'):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    print(f\"Original data size: {len(df)}\")\n",
    "\n",
    "    # 1. Null 값 제거\n",
    "    df = df.dropna()\n",
    "    print(f\"After removing Null values: {len(df)}\")\n",
    "\n",
    "    # 2. 이상치 제거 (ZeroDivisionError 방지 포함)\n",
    "    df = remove_outliers_iqr(df)\n",
    "\n",
    "    # 전처리된 데이터 저장\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Preprocessed data saved to '{output_file}' with {len(df)} rows.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_synthetic_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9ffc9-dd3a-4680-8357-e3c75090d6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
